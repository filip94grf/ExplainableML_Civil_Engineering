{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f69faf1-a3f5-4216-bcab-4e55769eea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXCEL_PATH = r\"D:\\FILIP\\DOKTORSKE STUDIJE\\III GODINA\\AIC M21 CASOPIS\\MATLAB CODE\\1.PRIPREMLJENA BAZA PODATAKA\\FUNDAMENTAL PERIOD PYTHON.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c9f741-41cd-45bf-92be-03ce3fe39e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great it works!\n",
    "\n",
    "# Can you now provide directly in the same way to jupyter-lab updated script for: \n",
    "# Script 6 — Genetic Programming Symbolic Regression (GEP-style)\n",
    "# Script 5 — LASSO Polynomial Regression (sparse closed-form)\n",
    "# Script 4 — Additive Spline GAM (explicit equation)\n",
    "# Script 3 — Model Tree (piecewise linear equations per region)\n",
    "# Script 2 — MARS (py-earth) to get piecewise-linear equations\n",
    "# Script 1 — Symbolic Regression (PySR) to discover equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821b86e8-9fcd-4ecf-aa1b-4f861cb98b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling Julia backend...\n",
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
      "   0    12.96      1.24416e+24       64          1368.62          1436.76     51.57s\n",
      "   1    10.98      1.48337e+09        9          950.406          859.706     40.52s\n",
      "   2    16.48      2.47054e+10        9          899.636          1257.38     38.45s\n",
      "   3    35.13      3.94666e+10       12          839.021          630.506     43.07s\n",
      "   4    35.26      5.21134e+11       12          791.698          1043.67     35.42s\n",
      "   5    28.87      9.29685e+13       12          789.466          1058.72     28.30s\n",
      "   6    25.28      5.65609e+10       22          766.298          898.252     19.14s\n",
      "   7    26.24      2.20434e+09       17          759.976          853.872     14.09s\n",
      "   8    25.14      3.47078e+08       17          707.811          728.153      6.52s\n",
      "   9    28.38      5.24119e+08       17          680.813          930.728      0.00s\n",
      "\n",
      "=== GP-Fallback — Symbolic Regression (original units) ===\n",
      "Train: {'R2': 0.902804, 'MAE': 504.362537, 'RMSE': 709.87914}\n",
      "Test : {'R2': 0.868902, 'MAE': 578.176751, 'RMSE': 860.944368}\n",
      "\n",
      "Closed-form (Python):\n",
      " y = ((pdiv(((t * B) * psqrt(fc)), plog(t)) - pdiv(L, 4.007)) - (t * fc))\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle y = \\frac{B t \\sqrt{\\left|{fc}\\right|} - \\left(0.249563264225215 L + fc t\\right) \\left(\\log{\\left(\\left|{t}\\right| + 1 \\right)} + 1.0 \\cdot 10^{-9}\\right)}{\\log{\\left(\\left|{t}\\right| + 1 \\right)} + 1.0 \\cdot 10^{-9}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Artifacts saved in: C:\\Users\\filip\\Documents\\POGLAVLJE KNJIGE\\out_symbolic_cfst\n",
      "Backend used: gplearn\n",
      "Running Time:  65.59984064102173  seconds\n"
     ]
    }
   ],
   "source": [
    "# JUPYTER CELL — Script 1: Symbolic Regression with pretty math display\n",
    "# Dataset: X = ['NoSt','NoSp','LoSp','OP','MWS'], y = 'TFP' (original units)\n",
    "\n",
    "import os, math, json, warnings, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start = time.time()\n",
    "# ---------- CONFIG ----------\n",
    "EXCEL_PATH = r\"D:\\FILIP\\DOKTORSKE STUDIJE\\IIIII GODINA\\8.CSP - NOVA KNJIGA SA VM\\MOJE POGLAVLJE\\CASE STUDIES\\CFST columns Dataset.xlsx\"\n",
    "SHEET = 0\n",
    "FEATURES = [\"B\",\"t\",\"L\",\"fy\",\"fc\"]\n",
    "TARGET = \"Nexp\"\n",
    "\n",
    "TEST_SIZE   = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# PySR knobs (used only if PySR+Julia available)\n",
    "PYSR_NITER     = 100\n",
    "PYSR_MAXSIZE   = 10\n",
    "PYSR_MAX_EVALS = 600\n",
    "PYSR_BIN_OPS   = [\"+\", \"-\", \"*\", \"/\", \"^\"]\n",
    "PYSR_UN_OPS    = [\"sqrt\"]\n",
    "PYSR_CONSTRAINTS = {\"^\": (5, 1)}\n",
    "\n",
    "# gplearn (fallback) knobs\n",
    "GP_POP_SIZE   = 5000\n",
    "GP_GENS       = 10\n",
    "GP_TOURN_SIZE = 20\n",
    "GP_PARSIMONY  = 0.001\n",
    "GP_CONST_MIN, GP_CONST_MAX = -5.0, 5.0\n",
    "\n",
    "OUTDIR = \"out_symbolic_cfst\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# ---------- LOAD DATA ----------\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET)\n",
    "missing = [c for c in FEATURES + [TARGET] if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in Excel: {missing}\\nPresent: {list(df.columns)}\")\n",
    "\n",
    "X = df[FEATURES].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "y = pd.to_numeric(df[TARGET], errors=\"coerce\").values\n",
    "mask = np.isfinite(X).all(axis=1) & np.isfinite(y)\n",
    "X, y = X[mask], y[mask]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "    return dict(\n",
    "        R2=r2_score(y_true, y_pred),\n",
    "        MAE=mean_absolute_error(y_true, y_pred),\n",
    "        RMSE=math.sqrt(((y_true - y_pred)**2).mean()),\n",
    "    )\n",
    "\n",
    "# ---------- Pretty math display (SymPy) ----------\n",
    "from sympy import sympify, Abs, sqrt, log, exp, latex, simplify, symbols\n",
    "from IPython.display import Math, display\n",
    "\n",
    "def show_math_equation(eq_py: str, var_order):\n",
    "    \"\"\"\n",
    "    Render 'y = <expr>' in proper math notation using SymPy.\n",
    "    Maps:\n",
    "      pdiv(a,b) -> a/(b + 1e-9)\n",
    "      psqrt(x)  -> sqrt(|x|)\n",
    "      plog(x)   -> log(1 + |x|)\n",
    "      pexp(x)   -> exp(x)\n",
    "    \"\"\"\n",
    "    # Create SymPy symbols for variables\n",
    "    syms = symbols(\" \".join(var_order), real=True)\n",
    "    loc = {name: sym for name, sym in zip(var_order, syms)}\n",
    "    # Map protected functions to SymPy expressions\n",
    "    loc.update({\n",
    "        \"pdiv\": lambda a, b: a/(b + 1e-9),\n",
    "        \"psqrt\": lambda x: sqrt(Abs(x)),\n",
    "        \"plog\": lambda x: log(1 + Abs(x)),\n",
    "        \"pexp\": lambda x: exp(x),\n",
    "    })\n",
    "    try:\n",
    "        expr = sympify(eq_py, locals=loc)\n",
    "        expr = simplify(expr)\n",
    "        display(Math(r\"y = \" + latex(expr)))\n",
    "    except Exception as e:\n",
    "        print(\"Could not render pretty math; showing raw expression instead.\")\n",
    "        print(\"y =\", eq_py)\n",
    "\n",
    "def save_results(name, eq_py, yhat_tr, yhat_te):\n",
    "    mt = metrics(y_te, yhat_te); mtr = metrics(y_tr, yhat_tr)\n",
    "    print(f\"\\n=== {name} — Symbolic Regression (original units) ===\")\n",
    "    print(\"Train:\", {k: round(v, 6) for k, v in mtr.items()})\n",
    "    print(\"Test :\", {k: round(v, 6) for k, v in mt.items()})\n",
    "    print(\"\\nClosed-form (Python):\\n\", \"y = \" + eq_py)\n",
    "    # Pretty math:\n",
    "    show_math_equation(eq_py, FEATURES)\n",
    "\n",
    "    with open(os.path.join(OUTDIR, f\"{name.lower()}_equation_python.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"y = \" + eq_py + \"\\n\")\n",
    "    with open(os.path.join(OUTDIR, f\"{name.lower()}_metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"train\": mtr, \"test\": mt}, f, indent=2)\n",
    "\n",
    "used_backend = None\n",
    "\n",
    "# ---------- Try PySR first ----------\n",
    "try:\n",
    "    from pysr import PySRRegressor\n",
    "\n",
    "    model = PySRRegressor(\n",
    "        niterations=PYSR_NITER,\n",
    "        maxsize=PYSR_MAXSIZE,\n",
    "        populations=30,\n",
    "        population_size=60,\n",
    "        parsimony=1e-4,\n",
    "        progress=True,\n",
    "        binary_operators=PYSR_BIN_OPS,\n",
    "        unary_operators=PYSR_UN_OPS,\n",
    "        loss=\"L2DistLoss()\",\n",
    "        model_selection=\"best\",\n",
    "        max_evals=PYSR_MAX_EVALS,\n",
    "        random_state=RANDOM_SEED,\n",
    "        constraints=PYSR_CONSTRAINTS,\n",
    "    ).fit(X_tr, y_tr, variable_names=FEATURES)\n",
    "\n",
    "    # Pick simplest within 5% of best test MAE\n",
    "    candidates = []\n",
    "    for _, row in model.equations_.iterrows():\n",
    "        # 'equation' is a Python-evaluable string produced by PySR (in terms of variable names)\n",
    "        eq_py = row[\"equation\"]\n",
    "        # Evaluate this candidate\n",
    "        f = model.lambda_format()(row[\"equation\"])\n",
    "        yhat_tr = np.array(f(X_tr), float)\n",
    "        yhat_te = np.array(f(X_te), float)\n",
    "        candidates.append({\n",
    "            \"complexity\": int(row[\"complexity\"]),\n",
    "            \"py\": eq_py,\n",
    "            \"train\": metrics(y_tr, yhat_tr),\n",
    "            \"test\":  metrics(y_te, yhat_te),\n",
    "            \"yhat_tr\": yhat_tr, \"yhat_te\": yhat_te\n",
    "        })\n",
    "    if not candidates:\n",
    "        raise RuntimeError(\"PySR returned no parsable equations.\")\n",
    "\n",
    "    best_mae = min(c[\"test\"][\"MAE\"] for c in candidates)\n",
    "    pool = [c for c in candidates if c[\"test\"][\"MAE\"] <= 1.05*best_mae]\n",
    "    best = sorted(pool, key=lambda c: (c[\"complexity\"], c[\"test\"][\"MAE\"]))[0]\n",
    "\n",
    "    used_backend = \"PySR\"\n",
    "    save_results(\"PySR\", best[\"py\"], best[\"yhat_tr\"], best[\"yhat_te\"])\n",
    "\n",
    "except Exception:\n",
    "    # ---------- Fallback: gplearn (pure Python) ----------\n",
    "    from gplearn.genetic import SymbolicRegressor\n",
    "    from gplearn.functions import make_function\n",
    "\n",
    "    def _pdiv(x, y):\n",
    "        return np.divide(x, np.where(np.abs(y) < 1e-9, np.sign(y)*1e-9 + (y==0)*1e-9, y))\n",
    "    def _psqrt(x):\n",
    "        return np.sqrt(np.abs(x))\n",
    "    def _plog(x):\n",
    "        return np.log1p(np.abs(x))\n",
    "    def _pexp(x):\n",
    "        return np.exp(np.clip(x, -20, 20))\n",
    "\n",
    "    pdiv = make_function(function=_pdiv, name=\"pdiv\", arity=2)\n",
    "    psqrt = make_function(function=_psqrt, name=\"psqrt\", arity=1)\n",
    "    plog  = make_function(function=_plog,  name=\"plog\",  arity=1)\n",
    "    pexp  = make_function(function=_pexp,  name=\"pexp\",  arity=1)\n",
    "\n",
    "    gp = SymbolicRegressor(\n",
    "        function_set=(\"add\",\"sub\",\"mul\",pdiv,psqrt,plog,pexp),\n",
    "        metric=\"rmse\",\n",
    "        population_size=GP_POP_SIZE,\n",
    "        generations=GP_GENS,\n",
    "        tournament_size=GP_TOURN_SIZE,\n",
    "        const_range=(GP_CONST_MIN, GP_CONST_MAX),\n",
    "        init_depth=(2,6),\n",
    "        init_method=\"half and half\",\n",
    "        p_crossover=0.8,\n",
    "        p_subtree_mutation=0.01,\n",
    "        p_hoist_mutation=0.01,\n",
    "        p_point_mutation=0.08,\n",
    "        parsimony_coefficient=GP_PARSIMONY,\n",
    "        max_samples=0.9,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    gp.fit(X_tr, y_tr)\n",
    "\n",
    "    # Convert gplearn program string to a Python-evaluable expression with your feature names\n",
    "    def program_to_python(expr_str, var_names):\n",
    "        s = expr_str\n",
    "        for i, n in enumerate(var_names):\n",
    "            s = re.sub(rf\"\\bX{i}\\b\", n, s)\n",
    "        s = s.replace(\"add(\", \"ADD(\").replace(\"sub(\", \"SUB(\").replace(\"mul(\", \"MUL(\")\n",
    "        def bin_to_infix(text, token, op):\n",
    "            while token in text:\n",
    "                idx = text.find(token + \"(\")\n",
    "                if idx == -1: break\n",
    "                depth, j, comma = 0, idx + len(token) + 1, None\n",
    "                while j < len(text):\n",
    "                    if text[j] == \"(\":\n",
    "                        depth += 1\n",
    "                    elif text[j] == \")\":\n",
    "                        if depth == 0: break\n",
    "                        depth -= 1\n",
    "                    elif text[j] == \",\" and depth == 0:\n",
    "                        comma = j; break\n",
    "                    j += 1\n",
    "                depth2, k = 0, comma + 1\n",
    "                while k < len(text):\n",
    "                    if text[k] == \"(\":\n",
    "                        depth2 += 1\n",
    "                    elif text[k] == \")\":\n",
    "                        if depth2 == 0: break\n",
    "                        depth2 -= 1\n",
    "                    k += 1\n",
    "                a = text[idx + len(token) + 1:comma]\n",
    "                b = text[comma + 1:k]\n",
    "                repl = \"(\" + a.strip() + f\" {op} \" + b.strip() + \")\"\n",
    "                text = text[:idx] + repl + text[k+1:]\n",
    "            return text\n",
    "        s = bin_to_infix(s, \"ADD\", \"+\")\n",
    "        s = bin_to_infix(s, \"SUB\", \"-\")\n",
    "        s = bin_to_infix(s, \"MUL\", \"*\")\n",
    "        return s\n",
    "\n",
    "    expr_str = str(gp._program)\n",
    "    eq_py = program_to_python(expr_str, FEATURES)\n",
    "\n",
    "    # Evaluate safely\n",
    "    def safe_eval_py(expr, Xmat, names):\n",
    "        env = {\n",
    "            \"np\": np,\n",
    "            \"pdiv\": lambda a,b: a/np.where(np.abs(b)<1e-9, np.sign(b)*1e-9 + (b==0)*1e-9, b),\n",
    "            \"psqrt\": lambda x: np.sqrt(np.abs(x)),\n",
    "            \"plog\":  lambda x: np.log1p(np.abs(x)),\n",
    "            \"pexp\":  lambda x: np.exp(np.clip(x, -20, 20)),\n",
    "        }\n",
    "        vals = {n: Xmat[:, i] for i, n in enumerate(names)}\n",
    "        return np.asarray(eval(expr, env, vals), float)\n",
    "\n",
    "    yhat_tr = safe_eval_py(eq_py, X_tr, FEATURES)\n",
    "    yhat_te = safe_eval_py(eq_py, X_te, FEATURES)\n",
    "\n",
    "    used_backend = \"gplearn\"\n",
    "    save_results(\"GP-Fallback\", eq_py, yhat_tr, yhat_te)\n",
    "\n",
    "print(f\"\\nArtifacts saved in: {os.path.abspath(OUTDIR)}\")\n",
    "print(\"Backend used:\", used_backend or \"unknown\")\n",
    "end = time.time()\n",
    "running_time = (end - start)\n",
    "print('Running Time: ', running_time, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36be204-72b7-426a-b328-1bdc3d25762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Controlling simplicity vs accuracy\n",
    "\n",
    "#Increase --max_evals / --niterations to search longer (find more accurate/possibly more complex formulas).\n",
    "\n",
    "#Lower --maxsize or raise parsimony (inside the script) to prefer simpler equations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
