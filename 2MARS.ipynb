{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f69faf1-a3f5-4216-bcab-4e55769eea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXCEL_PATH = r\"D:\\FILIP\\DOKTORSKE STUDIJE\\III GODINA\\AIC M21 CASOPIS\\MATLAB CODE\\1.PRIPREMLJENA BAZA PODATAKA\\FUNDAMENTAL PERIOD PYTHON.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c9f741-41cd-45bf-92be-03ce3fe39e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great it works!\n",
    "\n",
    "# Can you now provide directly in the same way to jupyter-lab updated script for: \n",
    "# Script 6 — Genetic Programming Symbolic Regression (GEP-style)\n",
    "# Script 5 — LASSO Polynomial Regression (sparse closed-form)\n",
    "# Script 4 — Additive Spline GAM (explicit equation)\n",
    "# Script 3 — Model Tree (piecewise linear equations per region)\n",
    "# Script 2 — MARS (py-earth) to get piecewise-linear equations\n",
    "# Script 1 — Symbolic Regression (PySR) to discover equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821b86e8-9fcd-4ecf-aa1b-4f861cb98b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MARS-style (degree=2) — Fundamental Period (TFP) ===\n",
      "KNOTS per feature (train): 4, quantile_range=(0.05, 0.95)\n",
      "Forward selected terms: 60 | Final after pruning: 38 | GCV=0.00840464\n",
      "Train: {'R2': 0.987401, 'MAE': 0.064017, 'RMSE': 0.087321}\n",
      "Test : {'R2': 0.987625, 'MAE': 0.065635, 'RMSE': 0.09037}\n",
      "\n",
      "Closed-form (Python):\n",
      " y = +0.6937573924984041 +0.001526200052396879*max((NoSt-6), 0)*max((OP-25), 0) +0.01311518631099621*max((NoSt-6), 0)*max((LoSp-3), 0) -0.0005215299061131011*max((LoSp-3), 0)*max((50-OP), 0) -0.06944806727625231*max((6-NoSt), 0) +0.0004154682972952098*max((NoSt-6), 0)*max((20-MWS), 0) +0.0001573012695363427*max((50-OP), 0)*max((MWS-4.5), 0) -0.001577514591693975*max((NoSt-6), 0)*max((25-OP), 0) +0.005251882080620267*max((NoSt-10), 0)*max((6-LoSp), 0) +0.001516587071822826*max((LoSp-3), 0)*max((OP-25), 0) +0.0005767088256495585*max((100-OP), 0)*max((7.5-MWS), 0) +0.01113570922812318*max((NoSt-14), 0)*max((4-NoSp), 0) +0.000753832730464259*max((6-NoSt), 0)*max((100-OP), 0) -0.01900237202305006*max((6-NoSt), 0)*max((LoSp-3), 0) -0.003934619324919602*max((6-LoSp), 0)*max((7.5-MWS), 0) -0.0006036308676178079*max((NoSt-6), 0)*max((OP-50), 0) -0.000399055233868234*max((14-NoSt), 0)*max((100-OP), 0) -0.001451820353015524*max((18-NoSt), 0)*max((6-NoSp), 0) -0.0004071144623710609*max((100-OP), 0)*max((MWS-7.5), 0) +0.0177731364708009*max((NoSt-14), 0)*max((4.5-LoSp), 0) -0.004057749544627759*max((OP-50), 0) -0.001668927885481061*max((10-NoSt), 0)*max((7.5-MWS), 0) +0.0002569373676408527*max((25-OP), 0)*max((MWS-12.0375), 0) -0.00343688029450227*max((10-NoSt), 0)*max((6-LoSp), 0) +0.0005679140875710288*max((50-OP), 0)*max((4.5-MWS), 0) +0.0001755096024264322*max((100-OP), 0)*max((MWS-12.0375), 0) +0.015678193084884*max((6-NoSp), 0)*max((6-LoSp), 0) -0.000619598510272716*max((25-OP), 0)*max((12.0375-MWS), 0) +0.002268300028690651*max((NoSp-4), 0)*max((MWS-4.5), 0) +0.001466953635616797*max((NoSt-10), 0)*max((7.5-MWS), 0) +0.0006593766601957191*max((6-NoSt), 0)*max((MWS-7.5), 0) +0.0006247456150418222*max((6-NoSt), 0)*max((50-OP), 0) +0.0003536467256304661*max((NoSt-14), 0)*max((100-OP), 0) -0.006264828884443167*max((10-NoSt), 0)*max((LoSp-6), 0) +0.00973138791394801*max((6-NoSt), 0)*max((LoSp-4.5), 0) -0.004918299466666761*max((NoSt-14), 0)*max((6-LoSp), 0) -0.0008371974055420855*max((6-LoSp), 0)*max((20-MWS), 0) -0.01442898227214206*max((NoSp-4), 0)*max((LoSp-4.5), 0) +0.001740506666386324*max((NoSp-4), 0)*max((20-MWS), 0)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle y = 0.0111357092281232 \\max\\left(0, 4 - NoSp\\right) \\max\\left(0, NoSt - 14\\right) + 0.0177731364708009 \\max\\left(0, 4.5 - LoSp\\right) \\max\\left(0, NoSt - 14\\right) + 0.000567914087571029 \\max\\left(0, 4.5 - MWS\\right) \\max\\left(0, 50 - OP\\right) + 0.015678193084884 \\max\\left(0, 6 - LoSp\\right) \\max\\left(0, 6 - NoSp\\right) - 0.0039346193249196 \\max\\left(0, 6 - LoSp\\right) \\max\\left(0, 7.5 - MWS\\right) - 0.00343688029450227 \\max\\left(0, 6 - LoSp\\right) \\max\\left(0, 10 - NoSt\\right) - 0.000837197405542086 \\max\\left(0, 6 - LoSp\\right) \\max\\left(0, 20 - MWS\\right) - 0.00491829946666676 \\max\\left(0, 6 - LoSp\\right) \\max\\left(0, NoSt - 14\\right) + 0.00525188208062027 \\max\\left(0, 6 - LoSp\\right) \\max\\left(0, NoSt - 10\\right) - 0.00145182035301552 \\max\\left(0, 6 - NoSp\\right) \\max\\left(0, 18 - NoSt\\right) + 0.000624745615041822 \\max\\left(0, 6 - NoSt\\right) \\max\\left(0, 50 - OP\\right) + 0.000753832730464259 \\max\\left(0, 6 - NoSt\\right) \\max\\left(0, 100 - OP\\right) + 0.00973138791394801 \\max\\left(0, 6 - NoSt\\right) \\max\\left(0, LoSp - 4.5\\right) - 0.0190023720230501 \\max\\left(0, 6 - NoSt\\right) \\max\\left(0, LoSp - 3\\right) + 0.000659376660195719 \\max\\left(0, 6 - NoSt\\right) \\max\\left(0, MWS - 7.5\\right) - 0.0694480672762523 \\max\\left(0, 6 - NoSt\\right) - 0.00166892788548106 \\max\\left(0, 7.5 - MWS\\right) \\max\\left(0, 10 - NoSt\\right) + 0.000576708825649558 \\max\\left(0, 7.5 - MWS\\right) \\max\\left(0, 100 - OP\\right) + 0.0014669536356168 \\max\\left(0, 7.5 - MWS\\right) \\max\\left(0, NoSt - 10\\right) - 0.00626482888444317 \\max\\left(0, 10 - NoSt\\right) \\max\\left(0, LoSp - 6\\right) - 0.000619598510272716 \\max\\left(0, 12.0375 - MWS\\right) \\max\\left(0, 25 - OP\\right) - 0.000399055233868234 \\max\\left(0, 14 - NoSt\\right) \\max\\left(0, 100 - OP\\right) + 0.00174050666638632 \\max\\left(0, 20 - MWS\\right) \\max\\left(0, NoSp - 4\\right) + 0.00041546829729521 \\max\\left(0, 20 - MWS\\right) \\max\\left(0, NoSt - 6\\right) + 0.000256937367640853 \\max\\left(0, 25 - OP\\right) \\max\\left(0, MWS - 12.0375\\right) - 0.00157751459169398 \\max\\left(0, 25 - OP\\right) \\max\\left(0, NoSt - 6\\right) - 0.000521529906113101 \\max\\left(0, 50 - OP\\right) \\max\\left(0, LoSp - 3\\right) + 0.000157301269536343 \\max\\left(0, 50 - OP\\right) \\max\\left(0, MWS - 4.5\\right) + 0.000175509602426432 \\max\\left(0, 100 - OP\\right) \\max\\left(0, MWS - 12.0375\\right) - 0.000407114462371061 \\max\\left(0, 100 - OP\\right) \\max\\left(0, MWS - 7.5\\right) + 0.000353646725630466 \\max\\left(0, 100 - OP\\right) \\max\\left(0, NoSt - 14\\right) - 0.0144289822721421 \\max\\left(0, LoSp - 4.5\\right) \\max\\left(0, NoSp - 4\\right) + 0.0131151863109962 \\max\\left(0, LoSp - 3\\right) \\max\\left(0, NoSt - 6\\right) + 0.00151658707182283 \\max\\left(0, LoSp - 3\\right) \\max\\left(0, OP - 25\\right) + 0.00226830002869065 \\max\\left(0, MWS - 4.5\\right) \\max\\left(0, NoSp - 4\\right) - 0.000603630867617808 \\max\\left(0, NoSt - 6\\right) \\max\\left(0, OP - 50\\right) + 0.00152620005239688 \\max\\left(0, NoSt - 6\\right) \\max\\left(0, OP - 25\\right) - 0.00405774954462776 \\max\\left(0, OP - 50\\right) + 0.693757392498404$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# JUPYTER CELL — Script 2: MARS-style (degree=2 with pairwise products), pure Python\n",
    "# Dataset: ['NoSt','NoSp','LoSp','OP','MWS'] -> TFP (original units)\n",
    "# Greedy forward selection + backward pruning using hinge and hinge*hinge bases.\n",
    "# Displays pretty math, prints metrics, and saves small artifacts.\n",
    "\n",
    "import os, json, math, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "EXCEL_PATH = r\"D:\\FILIP\\DOKTORSKE STUDIJE\\III GODINA\\AIC M21 CASOPIS\\MATLAB CODE\\1.PRIPREMLJENA BAZA PODATAKA\\FUNDAMENTAL PERIOD PYTHON.xlsx\"\n",
    "SHEET      = 0\n",
    "FEATURES   = [\"NoSt\",\"NoSp\",\"LoSp\",\"OP\",\"MWS\"]\n",
    "TARGET     = \"TFP\"\n",
    "\n",
    "TEST_SIZE   = 0.20\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Hinge candidate generation on TRAIN ONLY (then reused for TEST)\n",
    "# Make this smaller if runtime/memory is a concern; larger gives more flexibility.\n",
    "N_KNOTS_PER_FEATURE = 4            # interior knots per feature\n",
    "QUANTILE_RANGE      = (0.05, 0.95) # ignore tails\n",
    "\n",
    "# Forward / backward settings\n",
    "MAX_TERMS   = 60        # max number of basis terms (excluding intercept) to add in forward step\n",
    "MIN_IMPROV  = 1e-6      # stop forward when best RSS improvement below this\n",
    "PENALTY_GCV = 4.0       # GCV penalty (higher => simpler after pruning)\n",
    "\n",
    "OUTDIR = \"out_mars_style_degree2\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# ---------- LOAD DATA ----------\n",
    "df = pd.read_excel(EXCEL_PATH, sheet_name=SHEET)\n",
    "missing = [c for c in FEATURES + [TARGET] if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}\\nPresent: {list(df.columns)}\")\n",
    "\n",
    "X = df[FEATURES].apply(pd.to_numeric, errors=\"coerce\").values\n",
    "y = pd.to_numeric(df[TARGET], errors=\"coerce\").values\n",
    "mask = np.isfinite(X).all(axis=1) & np.isfinite(y)\n",
    "X, y = X[mask], y[mask]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "n_tr, p = X_tr.shape\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def metrics(y_true, y_pred):\n",
    "    return dict(\n",
    "        R2=r2_score(y_true, y_pred),\n",
    "        MAE=mean_absolute_error(y_true, y_pred),\n",
    "        RMSE=math.sqrt(((y_true - y_pred)**2).mean())\n",
    "    )\n",
    "\n",
    "def ols_fit(Z, y):\n",
    "    \"\"\"OLS with intercept; returns beta (incl. intercept), yhat and RSS.\"\"\"\n",
    "    Z1 = np.column_stack([np.ones(len(Z)), Z]) if Z.size else np.ones((len(y), 1))\n",
    "    beta, *_ = np.linalg.lstsq(Z1, y, rcond=None)\n",
    "    yhat = Z1 @ beta\n",
    "    rss = float(((y - yhat) ** 2).sum())\n",
    "    return beta, yhat, rss\n",
    "\n",
    "def gcv(rss, n, k, penalty=2.0):\n",
    "    \"\"\"MARS-like GCV: denom = (1 - (C/n))^2, with C = 1 + penalty*k (1 = intercept).\"\"\"\n",
    "    C = 1.0 + penalty * k\n",
    "    denom = (1.0 - C / n)\n",
    "    denom = max(denom, 1e-12)\n",
    "    return rss / (n * denom * denom)\n",
    "\n",
    "# ---------- TRAIN knots (for single hinges), then reuse ----------\n",
    "def compute_knots_train(Xtr, n_knots=10, qrange=(0.05, 0.95)):\n",
    "    knots_by_feature = []\n",
    "    q_lo, q_hi = qrange\n",
    "    qs = np.linspace(q_lo, q_hi, n_knots + 2)[1:-1]  # interior only\n",
    "    for j in range(Xtr.shape[1]):\n",
    "        x = Xtr[:, j]\n",
    "        ks = np.quantile(x, qs)\n",
    "        ks = np.unique(ks.round(12))\n",
    "        knots_by_feature.append(ks)\n",
    "    return knots_by_feature\n",
    "\n",
    "def build_single_hinges(Xmat, feature_names, knots_by_feature):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        Z_singles: (n x M1) matrix of single hinges\n",
    "        names_s:  list of 'h(<expr>)' strings\n",
    "        meta_s:   list of dicts with {'feat': j, 'knot': t, 'dir': +1/-1}\n",
    "    \"\"\"\n",
    "    Z_cols, names, meta = [], [], []\n",
    "    for j, name in enumerate(feature_names):\n",
    "        x = Xmat[:, j]\n",
    "        for t in knots_by_feature[j]:\n",
    "            Z_cols.append(np.maximum(0.0, x - t))\n",
    "            names.append(f\"h({name}-{t:.6g})\")\n",
    "            meta.append({\"feat\": j, \"knot\": float(t), \"dir\": +1})\n",
    "            Z_cols.append(np.maximum(0.0, t - x))\n",
    "            names.append(f\"h({t:.6g}-{name})\")\n",
    "            meta.append({\"feat\": j, \"knot\": float(t), \"dir\": -1})\n",
    "    if not Z_cols:\n",
    "        return np.empty((len(Xmat), 0)), [], []\n",
    "    return np.column_stack(Z_cols), names, meta\n",
    "\n",
    "def build_pair_hinges(Xmat, names_s, meta_s, idx_pairs):\n",
    "    \"\"\"\n",
    "    Multiply selected pairs of single hinges to form degree-2 interactions.\n",
    "    idx_pairs: list of (i, j) indices into the single-hinge basis.\n",
    "    Returns (Z_pairs, names_pairs).\n",
    "    \"\"\"\n",
    "    if not idx_pairs:\n",
    "        return np.empty((Xmat.shape[0], 0)), []\n",
    "    Z_cols, names = [], []\n",
    "    # We will regenerate the single hinges for Xmat from the names_s only when needed.\n",
    "    # But to be efficient, pass the already-built single hinges if available.\n",
    "    # For simplicity here, we compute them by evaluating the name string.\n",
    "    # However, we already have X_tr singles prebuilt; we'll use those for train,\n",
    "    # and rebuild for test using stored knots/meta.\n",
    "    raise_if = False  # placeholder to note that we shouldn't be here; we won't call this version.\n",
    "\n",
    "# Build TRAIN single hinges and their metadata\n",
    "knots_train = compute_knots_train(X_tr, N_KNOTS_PER_FEATURE, QUANTILE_RANGE)\n",
    "Zs_tr, names_s, meta_s = build_single_hinges(X_tr, FEATURES, knots_train)\n",
    "\n",
    "# Build TEST single hinges using the SAME knots\n",
    "def build_single_hinges_from_meta(Xmat, feature_names, meta_list):\n",
    "    Z_cols, names = [], []\n",
    "    for m in meta_list:\n",
    "        j, t, d = m[\"feat\"], m[\"knot\"], m[\"dir\"]\n",
    "        x = Xmat[:, j]\n",
    "        if d == +1:\n",
    "            Z_cols.append(np.maximum(0.0, x - t)); names.append(f\"h({feature_names[j]}-{t:.6g})\")\n",
    "        else:\n",
    "            Z_cols.append(np.maximum(0.0, t - x)); names.append(f\"h({t:.6g}-{feature_names[j]})\")\n",
    "    return np.column_stack(Z_cols), names\n",
    "\n",
    "Zs_te, _ = build_single_hinges_from_meta(X_te, FEATURES, meta_s)\n",
    "\n",
    "# Build PAIR indices across different features (degree=2)\n",
    "# To keep scale reasonable, we build all cross-feature pairs:\n",
    "single_count = len(names_s)\n",
    "feat_of = np.array([m[\"feat\"] for m in meta_s], dtype=int)\n",
    "pair_indices = []\n",
    "for i in range(single_count):\n",
    "    fi = feat_of[i]\n",
    "    for j in range(i+1, single_count):\n",
    "        fj = feat_of[j]\n",
    "        if fi != fj:  # cross-feature only (MARS degree=2)\n",
    "            pair_indices.append((i, j))\n",
    "\n",
    "# Construct TRAIN pair matrix (hinge_i * hinge_j)\n",
    "def multiply_pairs(Z_single, pair_idx_list):\n",
    "    if not pair_idx_list:\n",
    "        return np.empty((Z_single.shape[0], 0))\n",
    "    n = Z_single.shape[0]\n",
    "    Zp = np.empty((n, len(pair_idx_list)), dtype=float)\n",
    "    for k, (i, j) in enumerate(pair_idx_list):\n",
    "        Zp[:, k] = Z_single[:, i] * Z_single[:, j]\n",
    "    return Zp\n",
    "\n",
    "Zp_tr = multiply_pairs(Zs_tr, pair_indices)\n",
    "\n",
    "# Pair names for reporting\n",
    "names_p = [f\"{names_s[i]}*{names_s[j]}\" for (i, j) in pair_indices]\n",
    "\n",
    "# Build TEST pair matrix using TEST singles (same pairing structure)\n",
    "Zp_te = multiply_pairs(Zs_te, pair_indices)\n",
    "\n",
    "# Combine SINGLE + PAIR into full design\n",
    "Z_tr_full = np.column_stack([Zs_tr, Zp_tr])\n",
    "Z_te_full = np.column_stack([Zs_te, Zp_te])\n",
    "names_full = names_s + names_p\n",
    "\n",
    "# ---------- Forward selection ----------\n",
    "selected_idx = []\n",
    "current_Z = np.empty((n_tr, 0))\n",
    "beta, yhat, rss = ols_fit(current_Z, y_tr)\n",
    "fw_trace = [(selected_idx.copy(), beta.copy(), rss)]\n",
    "\n",
    "for step in range(MAX_TERMS):\n",
    "    best_improve = 0.0\n",
    "    best_j = None\n",
    "    # Try adding each unused candidate\n",
    "    for j in range(Z_tr_full.shape[1]):\n",
    "        if j in selected_idx:\n",
    "            continue\n",
    "        Z_try = np.column_stack([current_Z, Z_tr_full[:, j]])\n",
    "        _, _, rss_try = ols_fit(Z_try, y_tr)\n",
    "        improve = rss - rss_try\n",
    "        if improve > best_improve:\n",
    "            best_improve = improve\n",
    "            best_j = j\n",
    "    if best_j is None or best_improve < MIN_IMPROV:\n",
    "        break\n",
    "    selected_idx.append(best_j)\n",
    "    current_Z = np.column_stack([current_Z, Z_tr_full[:, best_j]])\n",
    "    beta, yhat, rss = ols_fit(current_Z, y_tr)\n",
    "    fw_trace.append((selected_idx.copy(), beta.copy(), rss))\n",
    "\n",
    "# ---------- Backward pruning (GCV) ----------\n",
    "def prune_backward(Z_full, y, selected):\n",
    "    snapshots = []\n",
    "    sel = selected.copy()\n",
    "    Z_sel = Z_full[:, sel] if sel else np.empty((len(y),0))\n",
    "    beta, _, rss = ols_fit(Z_sel, y)\n",
    "    k = len(sel)\n",
    "    snapshots.append((sel.copy(), beta.copy(), rss, gcv(rss, len(y), k, PENALTY_GCV)))\n",
    "\n",
    "    while len(sel) > 0:\n",
    "        best_gcv = float(\"inf\")\n",
    "        best_drop = None\n",
    "        best_beta = None\n",
    "        best_rss = None\n",
    "        for idx_pos in range(len(sel)):\n",
    "            trial = sel[:idx_pos] + sel[idx_pos+1:]\n",
    "            Z_trial = Z_full[:, trial] if trial else np.empty((len(y),0))\n",
    "            beta_t, _, rss_t = ols_fit(Z_trial, y)\n",
    "            gcv_t = gcv(rss_t, len(y), len(trial), PENALTY_GCV)\n",
    "            if gcv_t < best_gcv:\n",
    "                best_gcv = gcv_t\n",
    "                best_drop = idx_pos\n",
    "                best_beta = beta_t\n",
    "                best_rss = rss_t\n",
    "        sel.pop(best_drop)\n",
    "        snapshots.append((sel.copy(), best_beta.copy(), best_rss, best_gcv))\n",
    "    # choose snapshot with min GCV\n",
    "    return min(snapshots, key=lambda tup: tup[3])\n",
    "\n",
    "sel_fw, beta_fw, rss_fw = fw_trace[-1]\n",
    "sel_final, beta_final, rss_final, gcv_final = prune_backward(Z_tr_full, y_tr, sel_fw)\n",
    "\n",
    "# ---------- Predictions & metrics ----------\n",
    "def predict_from_indices(Z_full, beta, sel_idx):\n",
    "    if len(sel_idx) == 0:\n",
    "        Z1 = np.ones((Z_full.shape[0], 1))\n",
    "    else:\n",
    "        Z1 = np.column_stack([np.ones(Z_full.shape[0]), Z_full[:, sel_idx]])\n",
    "    return Z1 @ beta\n",
    "\n",
    "yhat_tr = predict_from_indices(Z_tr_full, beta_final, sel_final)\n",
    "yhat_te = predict_from_indices(Z_te_full, beta_final, sel_final)\n",
    "\n",
    "m_train = metrics(y_tr, yhat_tr)\n",
    "m_test  = metrics(y_te, yhat_te)\n",
    "\n",
    "# ---------- Pretty equation (SymPy) ----------\n",
    "from sympy import symbols, Max, sympify, latex\n",
    "from IPython.display import Math, display\n",
    "\n",
    "sym_vars = {name: symbols(name, real=True) for name in FEATURES}\n",
    "\n",
    "def hinge_name_to_sympy(nm: str):\n",
    "    inside = nm[nm.find(\"(\")+1: nm.rfind(\")\")]  # e.g., \"NoSt-3.2\" or \"3.2-NoSt\"\n",
    "    return Max(sympify(inside, locals=sym_vars), 0)\n",
    "\n",
    "# Decode whether a selected term is single or pair\n",
    "single_len = len(names_s)\n",
    "terms_report = [{\"term\": \"1 (intercept)\", \"coefficient\": float(beta_final[0])}]\n",
    "sym_expr = sympify(float(beta_final[0]))\n",
    "\n",
    "for pos, j in enumerate(sel_final, start=1):\n",
    "    nm = names_full[j]\n",
    "    c  = float(beta_final[pos])\n",
    "    if j < single_len:  # single hinge\n",
    "        term_expr = hinge_name_to_sympy(nm)\n",
    "    else:               # pair: \"h(..)*h(..)\"\n",
    "        left, right = nm.split(\"*\", 1)\n",
    "        term_expr = hinge_name_to_sympy(left) * hinge_name_to_sympy(right)\n",
    "    sym_expr += c * term_expr\n",
    "    terms_report.append({\"term\": nm, \"coefficient\": c})\n",
    "\n",
    "def python_equation(beta, sel_idx, names):\n",
    "    parts = [f\"{float(beta[0]):+.16g}\"]\n",
    "    for pos, j in enumerate(sel_idx, start=1):\n",
    "        nm = names[j]\n",
    "        if \"*\" in nm:\n",
    "            lft, rgt = nm.split(\"*\", 1)\n",
    "            in_l = lft[lft.find(\"(\")+1: lft.rfind(\")\")]\n",
    "            in_r = rgt[rgt.find(\"(\")+1: rgt.rfind(\")\")]\n",
    "            parts.append(f\"{float(beta[pos]):+.16g}*max(({in_l}), 0)*max(({in_r}), 0)\")\n",
    "        else:\n",
    "            inside = nm[nm.find(\"(\")+1: nm.rfind(\")\")]\n",
    "            parts.append(f\"{float(beta[pos]):+.16g}*max(({inside}), 0)\")\n",
    "    return \"y = \" + \" \".join(parts)\n",
    "\n",
    "eq_python = python_equation(beta_final, sel_final, names_full)\n",
    "\n",
    "# ---------- OUTPUT ----------\n",
    "print(\"=== MARS-style (degree=2) — Fundamental Period (TFP) ===\")\n",
    "print(f\"KNOTS per feature (train): {N_KNOTS_PER_FEATURE}, quantile_range={QUANTILE_RANGE}\")\n",
    "print(f\"Forward selected terms: {len(sel_fw)} | Final after pruning: {len(sel_final)} | GCV={gcv_final:.6g}\")\n",
    "print(\"Train:\", {k: round(v, 6) for k, v in m_train.items()})\n",
    "print(\"Test :\", {k: round(v, 6) for k, v in m_test.items()})\n",
    "print(\"\\nClosed-form (Python):\\n\", eq_python)\n",
    "\n",
    "# Pretty math in notebook\n",
    "display(Math(r\"y = \" + latex(sym_expr)))\n",
    "\n",
    "# ---------- Save artifacts ----------\n",
    "with open(os.path.join(OUTDIR, \"equation_python.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(eq_python + \"\\n\")\n",
    "pd.DataFrame(terms_report).to_csv(os.path.join(OUTDIR, \"terms_selected.csv\"), index=False)\n",
    "with open(os.path.join(OUTDIR, \"metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"file\": EXCEL_PATH,\n",
    "        \"sheet\": SHEET,\n",
    "        \"features\": FEATURES,\n",
    "        \"target\": TARGET,\n",
    "        \"degree\": 2,\n",
    "        \"n_knots_per_feature\": N_KNOTS_PER_FEATURE,\n",
    "        \"quantile_range\": QUANTILE_RANGE,\n",
    "        \"forward_max_terms\": MAX_TERMS,\n",
    "        \"penalty_gcv\": PENALTY_GCV,\n",
    "        \"forward_selected\": len(sel_fw),\n",
    "        \"final_selected\": len(sel_final),\n",
    "        \"train\": m_train,\n",
    "        \"test\":  m_test,\n",
    "        \"gcv_final\": gcv_final\n",
    "    }, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36be204-72b7-426a-b328-1bdc3d25762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complexity controls:\n",
    "\n",
    "# N_KNOTS_PER_FEATURE & QUANTILE_RANGE → candidate richness.\n",
    "\n",
    "# MAX_TERMS & MIN_IMPROV → forward stopping.\n",
    "\n",
    "# PENALTY_GCV → how aggressively the pruning simplifies the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
